{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed58c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams, EmbedTextParamsMetaNames\n",
    "\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import trafilatura\n",
    "import spacy\n",
    "from langchain.embeddings import LlamaCppEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa337e93",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c068ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite being one of the earlier machine learning techniques, linear regression continues to be a top choice among ML practitioners for a regression task. For the past three years, over 80% of the respondents to Kaggle’s annual state of data science and machine learning survey mentioned linear regression as a ML algorithm they most frequently use. IBM Db2 provides an in-database stored procedure (SP) for Linear Regression as part of its ML library, which is a collection of over 200 SPs for performing different ML tasks in the database. Using the linear regression SP and other functionality of DB2’s ML Library, ML practitioners can build and deploy linear regression models in the database when their ML dataset is available in a Db2 database. In this post, I will show you the following steps of building and using a linear regression pipeline using SQL with a Db2 database:\n",
      "Let’s begin.\n",
      "The Regression Task\n",
      "In this exercise, I will use the GoSales dataset, which is available from this link.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://community.ibm.com/community/user/blogs/shaikh-quader/2024/05/07/building-an-in-db-linear-regression-model-with-ibm'\n",
    "downloaded = trafilatura.fetch_url(url)\n",
    "\n",
    "if downloaded:\n",
    "    article = trafilatura.extract(downloaded)\n",
    "    print(article[:1000])  # Preview first 1000 chars\n",
    "else:\n",
    "    print(\"Failed to fetch content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2b1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea57bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_sentence_chunker(text, max_words=200, overlap_words=50):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        sentence = sentences[i]\n",
    "        sentence_length = len(sentence.split())\n",
    "\n",
    "        if current_length + sentence_length <= max_words:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "            i += 1\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            # Start new chunk with overlap\n",
    "            overlap = []\n",
    "            overlap_len = 0\n",
    "            j = len(current_chunk) - 1\n",
    "            while j >= 0 and overlap_len < overlap_words:\n",
    "                s = current_chunk[j]\n",
    "                overlap.insert(0, s)\n",
    "                overlap_len += len(s.split())\n",
    "                j -= 1\n",
    "            current_chunk = overlap\n",
    "            current_length = overlap_len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd8db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 chunks created.\n",
      "Despite being one of the earlier machine learning techniques, linear regression continues to be a top choice among ML practitioners for a regression task. For the past three years, over 80% of the respondents to Kaggle’s annual state of data science and machine learning survey mentioned linear regression as a ML algorithm they most frequently use. IBM Db2 provides an in-database stored procedure (SP) for Linear Regression as part of its ML library, which is a collection of over 200 SPs for performing different ML tasks in the database. Using the linear regression SP and other functionality of DB2’s ML Library, ML practitioners can build and deploy linear regression models in the database when their ML dataset is available in a Db2 database. In this post, I will show you the following steps of building and using a linear regression pipeline using SQL with a Db2 database:\n",
      "Let’s begin. The Regression Task\n",
      "In this exercise, I will use the GoSales dataset, which is available from this link. The dataset has 60252 synthetic customers’ profile and their purchase amount at an imaginary outdoor equipment store.\n"
     ]
    }
   ],
   "source": [
    "chunks = overlapping_sentence_chunker(article, max_words=200, overlap_words=50)\n",
    "print(f\"{len(chunks)} chunks created.\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa1e1f",
   "metadata": {},
   "source": [
    "## 2. Create a retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ca4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M2 Pro) - 21839 MiB free\n",
      "llama_model_loader: loaded meta data with 34 key-value pairs and 101 tensors from granite-embedding-30m-english-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = bert\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Granite Embedding 30m English\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = english\n",
      "llama_model_loader: - kv   4:                           general.basename str              = granite-embedding\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 30M\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,4]       = [\"language\", \"granite\", \"embeddings\",...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv   9:                           bert.block_count u32              = 6\n",
      "llama_model_loader: - kv  10:                        bert.context_length u32              = 512\n",
      "llama_model_loader: - kv  11:                      bert.embedding_length u32              = 384\n",
      "llama_model_loader: - kv  12:                   bert.feed_forward_length u32              = 1536\n",
      "llama_model_loader: - kv  13:                  bert.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv  14:          bert.attention.layer_norm_epsilon f32              = 0.000000\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  16:                      bert.attention.causal bool             = false\n",
      "llama_model_loader: - kv  17:                          bert.pooling_type u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = roberta-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,50265]   = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \".\"...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,50265]   = [3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 0\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  26:          tokenizer.ggml.seperator_token_id u32              = 2\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 1\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.cls_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.mask_token_id u32              = 50264\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = true\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.token_type_count u32              = 2\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   64 tensors\n",
      "llama_model_loader: - type q8_0:   31 tensors\n",
      "llama_model_loader: - type q6_K:    6 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 30.37 MiB (8.45 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control-looking token:  50260 '<|endoftext|>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
      "load: control token:  50264 '<mask>' is not marked as EOG\n",
      "load: control token:      3 '<unk>' is not marked as EOG\n",
      "load: control token:      1 '<pad>' is not marked as EOG\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      0 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 6\n",
      "load: token to piece cache size = 0.3060 MB\n",
      "print_info: arch             = bert\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 512\n",
      "print_info: n_embd           = 384\n",
      "print_info: n_layer          = 6\n",
      "print_info: n_head           = 12\n",
      "print_info: n_head_kv        = 12\n",
      "print_info: n_rot            = 32\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 32\n",
      "print_info: n_embd_head_v    = 32\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 384\n",
      "print_info: n_embd_v_gqa     = 384\n",
      "print_info: f_norm_eps       = 1.0e-12\n",
      "print_info: f_norm_rms_eps   = 0.0e+00\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 1536\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 0\n",
      "print_info: pooling type     = 2\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 512\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 22M\n",
      "print_info: model params     = 30.15 M\n",
      "print_info: general.name     = Granite Embedding 30m English\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 50265\n",
      "print_info: n_merges         = 50000\n",
      "print_info: BOS token        = 0 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: EOT token        = 50260 '<|endoftext|>'\n",
      "print_info: UNK token        = 3 '<unk>'\n",
      "print_info: SEP token        = 2 '</s>'\n",
      "print_info: PAD token        = 1 '<pad>'\n",
      "print_info: MASK token       = 50264 '<mask>'\n",
      "print_info: LF token         = 50118 'Ċ'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: EOG token        = 50260 '<|endoftext|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 100 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/7 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =    30.37 MiB\n",
      "...........................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 512\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 0\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x111498100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x111498530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x111765a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x2b68c43c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x1124f4280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x2b68c45f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x123bebaf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x173dd2b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x123bebef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x111765c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x11159d2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x1116933e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x111765f70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x2b68c4920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x1117661a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x111693630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x11159d520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x1114987a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x111766480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x2b579bb50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x123bd2ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x123bd2cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x123bd2f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x2b6948140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x123bd3150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x123bd3480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x12524af40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x173dd2f60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x12524b170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x12524b3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x123be85d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x12524b5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x123be8800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x173dd3190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x12524b800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x173dd33c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x12525a330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x173dd3740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x12526ac00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x1124f45b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x123be8a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x173dd3970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x173dd3ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x2b579bd80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x11159d750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x11159d980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x111498b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x2b68c4b50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x11159dcb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x11159dee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x2b3743f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x2b3740060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x2b3744e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x2b3745070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x2b579bfb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x111498f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x2b579c1e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x2b37452a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x2b68c4d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x2b68c4fb0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x2b37454d0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x2b68c51e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x2b579c410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x2b68c5410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x2b6948370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x2b69485a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x2b3745700 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x12526ae30 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x2b69487d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x125252430 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x173dd3dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x173dd41e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x173dd4410 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x173dd4640 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x173dd4870 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x173dd4aa0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x2b6948a00 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x123be8c60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x173dd4cd0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x2b68c5640 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x2b68c5870 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x123be8e90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x1124f47e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x2b6948c30 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x123be90c0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x125252660 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x123be92f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x2b6949170 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x1124f4a10 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x125252890 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x125252ac0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x125252cf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x2b3745930 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x123be9520 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x125257a90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x2b6948e60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x125257cc0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x2b3745b60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x2b3745d90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x1124f4d50 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x2b68c5aa0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x1124f4040 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x2b69493a0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x125257ef0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x2b69495d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x1124f50d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x2b6949800 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x125258120 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x125258350 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x125258580 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x2b6949a30 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x123be9750 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x1252587b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x2b6949c60 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x2b6949e90 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x2b694a0c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x123be9980 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x123be9bb0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x123be9de0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x2b694a2f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x2b3745fc0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x123bea010 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x123bea240 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x123bea470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x1252589e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x2b579c640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x1124f5300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x125258c10 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x2b37461f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x2b3746420 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x125258e40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x2b579c870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x2b579caa0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x1124f5790 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x125259070 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x2b579ccd0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x123bea6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x2b579cf00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x2b694a520 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x123be7f80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x123be81b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x1252592a0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x123be5cf0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x111499180 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x1114993b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x11159e110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x111693960 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x11159d0b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x1117666b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x2b3746650 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x1117668e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x11159e340 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x173dd4f00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x11159e970 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x1124f5530 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x1114997d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x111766b10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x1124f59c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x111766f90 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x111766d40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x1252594d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x11159eba0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x2b68c5fb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x173dd5130 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x125259700 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x2b694a750 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x173dd53d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x2b694a980 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x123be5f20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x2b694abb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x11159e570 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x173dd5600 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x125259930 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x173dd5830 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x123be6150 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x2b694adf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x2b68c5cd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x2b68c63f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x1124f5bf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x2b579d130 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x2b579b870 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x1124f5e20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x2b3746880 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x1124f6050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x1252552d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x173dd5a60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x111765800 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x2b579d530 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x111499a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x1117671c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x111499c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x125255500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x2b3746ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x2b68c6690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x1124f6280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x1124f64b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x2b68c68c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x123be6380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x1124f68f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x2b579d760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x1124f6b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x123be65b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x2b694b020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x173dd5c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x2b694b250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x2b579d990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x125255730 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x123be67e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x1124f6d50 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x123be6a10 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x1124f7070 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x123be6c40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x173dd5ec0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x2b68c6af0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x1124f72a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x125255960 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x173dd60f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x173dd6320 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x125255b90 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x2b68c6e00 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x2b694b480 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x125255dc0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x2b694b6b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x2b3746ce0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x2b579dbc0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x123be6e70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x123be70a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x123be72d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x2b694b8e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x125255ff0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x2b579ddf0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x2b3746f10 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x2b579e020 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x1116931a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x2b579e250 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x2b68c7030 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x2b579e480 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x1117674f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x2b694bb10 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x1124f74d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x2b3747140 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x2b694bd40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x123be7500 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x1124f7700 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x125256220 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x123be7730 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x111693cd0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x2b694bf70 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x2b68c7260 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x2b694c1a0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x2b694c3d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x2b694c600 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x1124f79a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x123be7960 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x2b579e6b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x123bd38f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x125256450 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x2b68c7490 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x125256680 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x1252568b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x125256ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x123bd3b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x2b694c830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x2b694ca60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x1124f7bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x125256d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x125256f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x2b694cc90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x2b694cec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x2b68c76c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x125257170 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x125257460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x173dd6550 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x125257690 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x1124f7f50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x173dd6860 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x2b68c78f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x111693f00 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x1124f8180 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x2b694d0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x2b694d320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x123b73bc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x125253370 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x2b694d550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x1252535a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x1252537d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x125253a00 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x173dd6a90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x1124f83b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x2b694d780 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x125253c30 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x173dd6cc0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x2b694d9b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x2b694dbe0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x2b3747370 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x2b3743160 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x2b694de10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x1124f85e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x11159ee10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x11159f040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x11159f270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x123b73df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x2b694e040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x123bd5e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x173dd6ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x125253e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x125254090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x1252542c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x2b694e270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x1252544f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x2b68c7b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x125254720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x2b694e610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x2b68c7d50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x2b694e840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x2b694eb70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x125254950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x125254b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x123bd6080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x125254db0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x2b694eda0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x2b579e8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x125254fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x125240510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x125240740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x123bd62b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x123bd64e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x125267f30 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.00 MiB\n",
      "create_memory: n_ctx = 512 (padded)\n",
      "llama_kv_cache_unified: kv_size = 512, type_k = 'f16', type_v = 'f16', n_layer = 6, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =     4.50 MiB\n",
      "llama_kv_cache_unified: KV self size  =    4.50 MiB, K (f16):    2.25 MiB, V (f16):    2.25 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:        CPU compute buffer size =    16.76 MiB\n",
      "llama_context: graph nodes  = 213\n",
      "llama_context: graph splits = 85 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.ggml.add_eos_token': 'true', 'tokenizer.ggml.add_bos_token': 'true', 'bert.feed_forward_length': '1536', 'tokenizer.ggml.padding_token_id': '1', 'tokenizer.ggml.seperator_token_id': '2', 'tokenizer.ggml.unknown_token_id': '3', 'tokenizer.ggml.pre': 'roberta-bpe', 'tokenizer.ggml.model': 'gpt2', 'bert.attention.causal': 'false', 'bert.attention.layer_norm_epsilon': '0.000000', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '0', 'bert.attention.head_count': '12', 'bert.embedding_length': '384', 'general.name': 'Granite Embedding 30m English', 'tokenizer.ggml.token_type_count': '2', 'bert.block_count': '6', 'general.quantization_version': '2', 'tokenizer.ggml.mask_token_id': '50264', 'general.license': 'apache-2.0', 'general.file_type': '18', 'general.finetune': 'english', 'tokenizer.ggml.cls_token_id': '0', 'general.architecture': 'bert', 'general.basename': 'granite-embedding', 'tokenizer.ggml.eos_token_id': '2', 'bert.pooling_type': '2', 'bert.context_length': '512', 'general.size_label': '30M'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =     153.94 ms\n",
      "llama_perf_context_print: prompt eval time =    2221.36 ms /  5487 tokens (    0.40 ms per token,  2470.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2236.83 ms /  5488 tokens\n"
     ]
    }
   ],
   "source": [
    "# Create LlamaCppEmbeddings instance\n",
    "embeddings = LlamaCppEmbeddings(model_path=\"granite-embedding-30m-english-Q6_K.gguf\")\n",
    "vectorstore = InMemoryVectorStore.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17db19",
   "metadata": {},
   "source": [
    "## 3. Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f521250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.getcwd()+\"/.env\", override=True)\n",
    "\n",
    "# Initialize the Watsonx chat model\n",
    "llm = ChatWatsonx(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    apikey=os.getenv(\"WATSONX_APIKEY\", \"\"),\n",
    "    model_id=\"mistralai/mistral-large\",\n",
    "    project_id=os.getenv(\"WATSONX_PROJECT\", \"\"),\n",
    "    params={\"temperature\": 0}  # match OpenAI config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd14a7",
   "metadata": {},
   "source": [
    "## 4. Generate query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c5aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to call the model with tool use\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"Call the Watsonx mistral model to generate a response based on the current state.\n",
    "    It will decide to use the retriever tool or respond directly.\n",
    "    \"\"\"\n",
    "    response = (\n",
    "        llm\n",
    "        .bind_tools([retriever_tool])\n",
    "        .invoke(state[\"messages\"])\n",
    "    )\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada0555",
   "metadata": {},
   "source": [
    "## 5. Grade documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1947db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question. \\n \"\n",
    "    \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
    "    \"Here is the user question: {question} \\n\"\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\"\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "def grade_documents(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = (\n",
    "        llm\n",
    "        .with_structured_output(GradeDocuments).invoke(\n",
    "            [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    )\n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0bfc4",
   "metadata": {},
   "source": [
    "## 6. Rewrite question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4db64143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"{question}\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"Formulate an improved question:\"\n",
    ")\n",
    "\n",
    "# Rewrite function using Watsonx\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"Rewrite the original user question using Watsonx.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "\n",
    "    # Invoke Watsonx model with formatted prompt\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"user\", \"content\": response.content}]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e40ce1",
   "metadata": {},
   "source": [
    "## 7. Generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68d67d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "    \"Question: {question} \\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"Generate an answer.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be9351",
   "metadata": {},
   "source": [
    "## 8. Assemble the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20484e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(generate_query_or_respond)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(rewrite_question)\n",
    "workflow.add_node(generate_answer)\n",
    "\n",
    "workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query_or_respond\",\n",
    "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2576967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f66c34",
   "metadata": {},
   "source": [
    "## 9. Run the agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9479dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     153.94 ms\n",
      "llama_perf_context_print: prompt eval time =      19.14 ms /    12 tokens (    1.59 ms per token,   627.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      20.14 ms /    13 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (agwNbsQJY)\n",
      " Call ID: agwNbsQJY\n",
      "  Args:\n",
      "    query: How to calculate summary statistics in Db2?\n",
      "\n",
      "\n",
      "\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "I am calling this SP with these parameters: (1) intable: name of the table whose sumary statistics I want to gather, the training partition in this case; (2) outtable: name of the table where I want the SP to store the overall summary statistics, (3) incolumn: list of columns whose statistics I want to collect. SUMMARY1000 SP saves the collected statistics from the training table in three output tables: (1) GOSALES_TRAIN_SUM1000: has summary statistics of all columns listed in the incolumn parameter; (2) GOSALES_TRAIN_SUM1000_NUM: has summary statistics of only the numeric columns from the incolumn parameter, (3) GOSALES_TRAIN_SUM1000_CHAR: has summary statistics of categorical columns from the incolumn parameter. For the ease of viewing, I will look at the summary statistics of each column type separately — first the numeric type and then nominal type. SELECT * FROM GOSALES.GOSALES_TRAIN_SUM1000_NUM The dataset has one numeric feature column, AGE. This summary table has provides a range of statistics, such as mean, variance, skewness. Also, the table reports that the AGE column has 1878 missing values. Similarly, I find the following summary statistics from the GOSALES.GOSALES_TRAIN_SUM1000_CHAR table.\n",
      "\n",
      "Data Exploration\n",
      "Now, I will look into some sample records from the training dataset, GOSALES_TRAIN. SELECT * FROM GOSALES.GOSALES_TRAIN FETCH FIRST 5 ROWS ONLY\n",
      "From the above sample records, I get a feel for the customer records I will work with. Next, I will generate summary statistics of the entire training set using SUMMARY1000 SP:\n",
      "CALL IDAX.SUMMARY1000('intable=GOSALES.GOSALES_TRAIN, outtable=GOSALES.GOSALES_TRAIN_SUM1000, incolumn=GENDER;AGE;MARITAL_STATUS;PROFESSION') In this SP call, intable parameter has the name of the training table from which I wanted to gather summary statistics. outtable parameter has the name of the output table where I want the SP to save the summary statistics of the entire training table. In the incolumn parameter, I list the columns whose statistics I want to collect. I am calling this SP with these parameters: (1) intable: name of the table whose sumary statistics I want to gather, the training partition in this case; (2) outtable: name of the table where I want the SP to store the overall summary statistics, (3) incolumn: list of columns whose statistics I want to collect.\n",
      "\n",
      "For the ease of viewing, I will look at the summary statistics of each column type separately — first the numeric type and then nominal type. SELECT * FROM GOSALES.GOSALES_TRAIN_SUM1000_NUM The dataset has one numeric feature column, AGE. This summary table has provides a range of statistics, such as mean, variance, skewness. Also, the table reports that the AGE column has 1878 missing values. Similarly, I find the following summary statistics from the GOSALES.GOSALES_TRAIN_SUM1000_CHAR table. SELECT * FROM GOSALES.GOSALES_TRAIN_SUM1000_CHAR\n",
      "From this summary, I can see that all three nominal columns have some missing values. Data Preprocessing\n",
      "From data exploration, I identified two kinds of data preprocessing tasks: handling missing values and dealing with nominal columns. In this step, I will address both tasks. Dealing with missing values\n",
      "I will replace missing values in the training dataset using IMPUTE_DATA SP. This SP supports replacing missing values with one of the four methods: mean, median, most frequent value, or a constant. All four methods work with numeric columns, whereas only the last two methods apply to nominal columns. AGE column: I will replace missing values in the AGE column with the mean age value:\n",
      "CALL IDAX.IMPUTE_DATA('intable=GOSALES.GOSALES_TRAIN, incolumn=AGE, method=mean')\n",
      "\n",
      "The value is GOSALES_FULL; (2) id: the name of the id column in the input table; (3) traintable: the name I want to give to the table that will have the training records; (4) testtable: the name of the output table where the SP will store the test records; (5) fraction: the portion of the records that I want in the training partition; (6) seed: I can set a value for reproducibility of the same partitions. The SP will randomly divide records from the GOSALES_FULL table into two output tables: GOSALES_TRAIN and GOSALES_TEST. The following two SQL statements will count the number of records in these two tables. SELECT count(*) FROM GOSALES.GOSALES_TRAIN\n",
      "SELECT count(*) FROM GOSALES.GOSALES_TEST\n",
      "The above counts confirm that the train and test tables have 80% and 20% of records, respectively, from the original table with 60252 records. Data Exploration\n",
      "Now, I will look into some sample records from the training dataset, GOSALES_TRAIN. SELECT * FROM GOSALES.GOSALES_TRAIN FETCH FIRST 5 ROWS ONLY\n",
      "From the above sample records, I get a feel for the customer records I will work with. Next, I will generate summary statistics of the entire training set using SUMMARY1000 SP:\n",
      "CALL IDAX.SUMMARY1000('intable=GOSALES.GOSALES_TRAIN, outtable=GOSALES.GOSALES_TRAIN_SUM1000, incolumn=GENDER;AGE;MARITAL_STATUS;PROFESSION')\n",
      "\n",
      "\n",
      "\n",
      "Update from node generate_answer\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " To calculate summary statistics in Db2, you can use the stored procedure `SUMMARY1000`. This procedure takes parameters such as `intable` (the input table), `outtable` (the output table for statistics), and `incolumn` (the list of columns to analyze). It generates summary statistics for the specified columns and stores them in the output table. For example, you can call it like this: `CALL IDAX.SUMMARY1000('intable=GOSALES.GOSALES_TRAIN, outtable=GOSALES.GOSALES_TRAIN_SUM1000, incolumn=GENDER;AGE;MARITAL_STATUS;PROFESSION')`.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How to calculate summary statistics in Db2?\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    for node, update in chunk.items():\n",
    "        print(\"Update from node\", node)\n",
    "        update[\"messages\"][-1].pretty_print()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86713804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     153.94 ms\n",
      "llama_perf_context_print: prompt eval time =       4.50 ms /    15 tokens (    0.30 ms per token,  3333.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =       4.69 ms /    16 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (8asdrjp8I)\n",
      " Call ID: 8asdrjp8I\n",
      "  Args:\n",
      "    query: How to build a linear regression model with IBM Db2?\n",
      "\n",
      "\n",
      "\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Despite being one of the earlier machine learning techniques, linear regression continues to be a top choice among ML practitioners for a regression task. For the past three years, over 80% of the respondents to Kaggle’s annual state of data science and machine learning survey mentioned linear regression as a ML algorithm they most frequently use. IBM Db2 provides an in-database stored procedure (SP) for Linear Regression as part of its ML library, which is a collection of over 200 SPs for performing different ML tasks in the database. Using the linear regression SP and other functionality of DB2’s ML Library, ML practitioners can build and deploy linear regression models in the database when their ML dataset is available in a Db2 database. In this post, I will show you the following steps of building and using a linear regression pipeline using SQL with a Db2 database:\n",
      "Let’s begin. The Regression Task\n",
      "In this exercise, I will use the GoSales dataset, which is available from this link. The dataset has 60252 synthetic customers’ profile and their purchase amount at an imaginary outdoor equipment store.\n",
      "\n",
      "In this post, I will show you the following steps of building and using a linear regression pipeline using SQL with a Db2 database:\n",
      "Let’s begin. The Regression Task\n",
      "In this exercise, I will use the GoSales dataset, which is available from this link. The dataset has 60252 synthetic customers’ profile and their purchase amount at an imaginary outdoor equipment store. The following is the list of columns in the dataset:\n",
      "I want to learn a multiple linear regression function of the following equation form that will use as input the first four columns — AGE, MARITAL_STATUS, and PROFESSION — and predict the PURCHASE_AMOUNT. Using the training examples, the linear regression algorithm will learn the values of the following five parameters — the first one is the intercept and the remaining are four coefficients, one per input column. Following these steps, I created a Db2 table with the name GOSALES_FULL under GOSALES schema and loaded the dataset into it. Train / Test Split\n",
      "First, I will divide the records from the GOSALES_FULL table into two partitions: a training partition and a test partition. For making these partitions, I will call the SPLIT_DATA stored procedure (SP) as follows.\n",
      "\n",
      "A.PURCHASE_AMOUNT * 100) AS MAPE FROM GOSALES.GOSALES_TEST AS A, GOSALES.GOSALES_TEST_PREDICTIONS AS B WHERE A.ID = B.ID\n",
      "Dropping the Model\n",
      "If I want to drop this model, I can use the DROP_MODEL SP:\n",
      "CALL IDAX.DROP_MODEL('model=GOSALES.GOSALES_LINREG')\n",
      "Conclusion\n",
      "In this exercise, I built, evaluated, and deployed an end-to-end linear regression pipeline using 29 simple SQL queries — 17 of them are calls to SPs provided by Db2, and the remaining ones were SELECT statements. In this ML workflow, I didn’t need to bring any data outside of the database, nor did I need separate infrastructure for developing, training, and serving ML models. For many companies, machine learning in the database can be a cost effective and quicker path to embrace AI.\n",
      "Related Resources\n",
      "For creating an in-database ML pipeline using my above steps, you can download the GoSales dataset from this link and follow instructions on this page to set up a Db2 database. To learn more about Db2’s in-database ML library, check out Db2 production documentation. To find more examples of creating in-database ML models with Db2, check out this GitHub repo. #Featured-area-2\n",
      "\n",
      "Model Training\n",
      "The following call to the LINEAR_REGRESSION SP will begin training of a linear regression model using training examples from the GOSALES_TRAIN table. The SP will use the list of columns mentioned in the incolum paramter as input features and the column from the target parameter as the output column. Since the intercept parameter is set to true, the SP will learn the value of intercept. CALL IDAX.LINEAR_REGRESSION('model=GOSALES.GOSALES_LINREG, intable=GOSALES.GOSALES_TRAIN, id=ID, target=PURCHASE_AMOUNT,incolumn=AGE;GENDER;MARITAL_STATUS;PROFESSION, intercept=true') After the training completes, the SP will add the new model, GOSALES_LINREG, to Db2’s model catalog. The following SP call will show the list of existing models in the catalog, which now includes my new model. CALL IDAX.LIST_MODELS('format=short, all=true')\n",
      "Additionally, the LINEAR_REGRESSION SP saves the learned values of intercept and the coefficients, along with several other learned parameter values, in a table. The table’s name takes this form: MODELNAME_MODEL. For the GOSALES_LINREG model, the name of its metadata table is GOSALES_LINREG_MODEL. The following SQL will display the values of the learned model parameters. SELECT VAR_NAME, LEVEL_NAME, VALUE FROM GOSALES.GOSALES_LINREG_MODEL You may have noticed that the above output has more feature columns than what I originally had in the training set.\n",
      "\n",
      "\n",
      "\n",
      "Update from node generate_answer\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " To build a linear regression model with IBM Db2, you can use the in-database stored procedure (SP) for Linear Regression provided by Db2's ML library. First, create a table and load your dataset. Then, split the data into training and test partitions using the `SPLIT_DATA` SP. Finally, train the linear regression model using the `LINEAR_REGRESSION` SP, specifying the input columns and target column. For example:\n",
      "\n",
      "```sql\n",
      "CALL IDAX.LINEAR_REGRESSION('model=GOSALES.GOSALES_LINREG, intable=GOSALES.GOSALES_TRAIN, id=ID, target=PURCHASE_AMOUNT, incolumn=AGE;GENDER;MARITAL_STATUS;PROFESSION, intercept=true')\n",
      "```\n",
      "\n",
      "After training, the model will be added to Db2's model catalog, and you can view the learned parameters using a SQL query.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How to build a linear regression model with IBM Db2?\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    for node, update in chunk.items():\n",
    "        print(\"Update from node\", node)\n",
    "        update[\"messages\"][-1].pretty_print()\n",
    "        print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
